{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic \n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "holistic = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    image.flags.writeable = False                  \n",
    "    results = model.process(image)                 \n",
    "    image.flags.writeable = True                  \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) \n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results,draw=True):\n",
    "      if draw:\n",
    "        # Draw face connections\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                                mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)) \n",
    "        # Draw pose connections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                                mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)) \n",
    "        #Draw left hand connections\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                                mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)) \n",
    "        # Draw right hand connections  \n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_keypoints(results):\n",
    "#     pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "#     face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "#     lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "#     rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "#     return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypointsL(results):\n",
    "   \n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    \n",
    "    return np.concatenate([lh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypointsR(results):\n",
    "    \n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('NumberR.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "# def prob_viz(res, actions, input_frame, colors):\n",
    "#     output_frame = input_frame.copy()\n",
    "#     for num, prob in enumerate(res):\n",
    "#         cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "#         cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)       \n",
    "#     return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def symbolRight(image, holistic):\n",
    "    frame_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = holistic.process(frame_rgb)\n",
    "    \n",
    "    if results.right_hand_landmarks and results.pose_landmarks:\n",
    "        left_hand_landmarks = results.right_hand_landmarks\n",
    "        wrist_x = int(left_hand_landmarks.landmark[mp_holistic.HandLandmark.WRIST].x * image.shape[1])\n",
    "        wrist_y = int(left_hand_landmarks.landmark[mp_holistic.HandLandmark.WRIST].y * image.shape[0])\n",
    "        \n",
    "        # Access the landmark for the base of the middle finger\n",
    "        middle_finger_base_x = int(left_hand_landmarks.landmark[mp_holistic.HandLandmark.MIDDLE_FINGER_MCP].x * image.shape[1])\n",
    "        middle_finger_base_y = int(left_hand_landmarks.landmark[mp_holistic.HandLandmark.MIDDLE_FINGER_MCP].y * image.shape[0])\n",
    "\n",
    "        palm_center_x = int((wrist_x + middle_finger_base_x) / 2)\n",
    "        palm_center_y = int((wrist_y + middle_finger_base_y) / 2)\n",
    "        symbol_x = palm_center_x - 10\n",
    "        symbol_y = palm_center_y - 20\n",
    "        \n",
    "        font = ImageFont.truetype('SuttonSignWriting.ttf', 80)\n",
    "        font_color = (0, 0, 0)  # Default color (black)\n",
    "        font_style = \"normal\"    # Default style (normal)\n",
    "        \n",
    "        if hasattr(font, \"color\"):\n",
    "            font_color = font.color\n",
    "        if hasattr(font, \"style\"):\n",
    "            font_style = font.style\n",
    "        \n",
    "        pil_frame = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        draw = ImageDraw.Draw(pil_frame)\n",
    "          \n",
    "        selected_index = np.argmax(res)\n",
    "        selected_hex_string = actions[selected_index]\n",
    "        hex_int = int(selected_hex_string, 16)\n",
    "        symbol = chr(hex_int)\n",
    "        \n",
    "        symbol_position = (symbol_x, symbol_y)\n",
    "        \n",
    "        draw.text(symbol_position, symbol, font=font, fill=font_color, anchor=\"mm\", align=\"center\", spacing=0)\n",
    "        image = cv2.cvtColor(np.array(pil_frame), cv2.COLOR_RGB2BGR)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def symbolLeftt(image, holistic):\n",
    "    frame_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = holistic.process(frame_rgb)\n",
    "    \n",
    "    if results.left_hand_landmarks and results.pose_landmarks:\n",
    "        left_hand_landmarks = results.left_hand_landmarks\n",
    "        wrist_x = int(left_hand_landmarks.landmark[mp_holistic.HandLandmark.WRIST].x * image.shape[1])\n",
    "        wrist_y = int(left_hand_landmarks.landmark[mp_holistic.HandLandmark.WRIST].y * image.shape[0])\n",
    "        \n",
    "        # Access the landmark for the base of the middle finger\n",
    "        middle_finger_base_x = int(left_hand_landmarks.landmark[mp_holistic.HandLandmark.MIDDLE_FINGER_MCP].x * image.shape[1])\n",
    "        middle_finger_base_y = int(left_hand_landmarks.landmark[mp_holistic.HandLandmark.MIDDLE_FINGER_MCP].y * image.shape[0])\n",
    "\n",
    "        palm_center_x = int((wrist_x + middle_finger_base_x) / 2)\n",
    "        palm_center_y = int((wrist_y + middle_finger_base_y) / 2)\n",
    "        symbol_x = palm_center_x - 10\n",
    "        symbol_y = palm_center_y - 20\n",
    "        \n",
    "        font = ImageFont.truetype('SuttonSignWriting.ttf', 80)\n",
    "        font_color = (0, 0, 0)  # Default color (black)\n",
    "        font_style = \"normal\"    # Default style (normal)\n",
    "        \n",
    "        if hasattr(font, \"color\"):\n",
    "            font_color = font.color\n",
    "        if hasattr(font, \"style\"):\n",
    "            font_style = font.style\n",
    "        \n",
    "        pil_frame = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        draw = ImageDraw.Draw(pil_frame)\n",
    "        \n",
    "        selected_index = np.argmax(res)\n",
    "        selected_hex_string = actions[selected_index]\n",
    "        hex_int = int(selected_hex_string, 16)\n",
    "        symbol = chr(hex_int)\n",
    "        \n",
    "        symbol_position = (symbol_x, symbol_y)\n",
    "        \n",
    "        draw.text(symbol_position, symbol, font=font, fill=font_color, anchor=\"mm\", align=\"center\", spacing=0)\n",
    "        image = cv2.cvtColor(np.array(pil_frame), cv2.COLOR_RGB2BGR)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('NumberR.txt', 'r') as file:\n",
    "    actions = np.array([line.strip().split(',')[0] for line in file.readlines()])\n",
    "with open('NumberR.txt', 'r') as file:\n",
    "    actions1 = np.array([line.strip().split(',')[1] for line in file.readlines()])\n",
    "\n",
    "no_sequences = 10\n",
    "\n",
    "# Videos are going to be 5 frames in length\n",
    "sequence_length = 5\n",
    "print(actions)\n",
    "print(actions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detection\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.5\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame,1)\n",
    "\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "\n",
    "        draw_styled_landmarks(image, results,draw=False)\n",
    "            \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypointsL(results)\n",
    "\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-5:]\n",
    "                \n",
    "        if len(sequence) == 5:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "                \n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                frame_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = symbolRight(image,holistic)\n",
    "                #image = symbolLeftt(image,holistic)    \n",
    "            if len(sentence) > 0: \n",
    "                if actions1[np.argmax(res)] != sentence[-1]:\n",
    "                    sentence.append(actions1[np.argmax(res)])\n",
    "            else:\n",
    "                sentence.append(actions1[np.argmax(res)])                \n",
    "            if len(sentence) > 5:\n",
    "                sentence = sentence[-5:]\n",
    "                \n",
    "                # Viz probabilities\n",
    "                #image = prob_viz(res, actions1, image, colors)\n",
    "                    \n",
    "            cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "            cv2.putText(image, sentence[-1], (3,30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 25, 255), 2, cv2.LINE_AA)                   \n",
    "            # Show to screen\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "            # Break\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyPhyton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
